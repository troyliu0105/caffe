name: "ResNet-18"
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
	  force_color: true
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 320
      width: 320
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 352
      width: 352
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 384
      width: 384
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 416
      width: 416
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 448
      width: 448
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 480
      width: 480
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 512
      width: 512
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 544
      width: 544
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
	  resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 576
      width: 576
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    resize_param {
      prob: 0.1
      resize_mode: WARP
      height: 608
      width: 608
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32.0
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18.0
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0.5
    }
    noise_param {
      hist_eq: true
      hist_eq_prob: 0.5
      inverse: false
      decolorize: false
      gauss_blur: true
      gauss_blur_prob: 0.15
      posterize: false
      saltpepper: true
      saltpepper_prob: 0.25
      saltpepper_param {
        fraction: 0.01
      }
      convert_to_hsv: false
    }
  }
  data_param {
    source: "data/VOC0712/VOC0712_trainval_lmdb"
    batch_size: 4
    prefetch: 4
    backend: LMDB
  }
  annotated_data_param {
	  yolo_data_type : 1
	  yolo_data_jitter : 0.3
    label_map_file:  "data/VOC0712/labelmap_voc.prototxt"
  }
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
	  force_color: true
    resize_param {
      prob: 1.0
      resize_mode: WARP
      height: 416
      width: 416
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "data/VOC0712/VOC0712_test_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {}
    label_map_file:  "data/VOC0712/labelmap_voc.prototxt"
  }
}

layer {
  bottom: "data"
  top: "conv1"
  name: "conv1"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "conv1"
  top: "conv1"
  name: "bn_conv1"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "conv1"
  top: "conv1"
  name: "scale_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "conv1"
  top: "conv1"
  name: "conv1_relu"
  type: "ReLU"
}

layer {
  bottom: "conv1"
  top: "pool1"
  name: "pool1"
  type: "Pooling"
  pooling_param {
    kernel_size: 3
    stride: 2
    pool: MAX
  }
}

layer {
  bottom: "pool1"
  top: "res2a_branch1"
  name: "res2a_branch1"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  name: "bn2a_branch1"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  name: "scale2a_branch1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "pool1"
  top: "res2a_branch2a"
  name: "res2a_branch2a"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  name: "bn2a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  name: "scale2a_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  name: "res2a_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  name: "res2a_branch2b"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  name: "bn2a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  name: "scale2a_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res2a_branch1"
  bottom: "res2a_branch2b"
  top: "res2a"
  name: "res2a"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res2a"
  top: "res2a"
  name: "res2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res2a"
  top: "res2b_branch2a"
  name: "res2b_branch2a"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  name: "bn2b_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  name: "scale2b_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  name: "res2b_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  name: "res2b_branch2b"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  name: "bn2b_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  name: "scale2b_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res2a"
  bottom: "res2b_branch2b"
  top: "res2b"
  name: "res2b"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res2b"
  top: "res2b"
  name: "res2b_relu"
  type: "ReLU"
}

layer {
  bottom: "res2b"
  top: "res3a_branch1"
  name: "res3a_branch1"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    pad: 0
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  name: "bn3a_branch1"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  name: "scale3a_branch1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res2b"
  top: "res3a_branch2a"
  name: "res3a_branch2a"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  name: "bn3a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  name: "scale3a_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  name: "res3a_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  name: "res3a_branch2b"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  name: "bn3a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  name: "scale3a_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res3a_branch1"
  bottom: "res3a_branch2b"
  top: "res3a"
  name: "res3a"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res3a"
  top: "res3a"
  name: "res3a_relu"
  type: "ReLU"
}

layer {
  bottom: "res3a"
  top: "res3b_branch2a"
  name: "res3b_branch2a"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  name: "bn3b_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  name: "scale3b_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  name: "res3b_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  name: "res3b_branch2b"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  name: "bn3b_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  name: "scale3b_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res3a"
  bottom: "res3b_branch2b"
  top: "res3b"
  name: "res3b"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res3b"
  top: "res3b"
  name: "res3b_relu"
  type: "ReLU"
}

layer {
  bottom: "res3b"
  top: "res4a_branch1"
  name: "res4a_branch1"
  type: "Convolution"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    pad: 0
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  name: "bn4a_branch1"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  name: "scale4a_branch1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res3b"
  top: "res4a_branch2a"
  name: "res4a_branch2a"
  type: "Convolution"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
        type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  name: "bn4a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  name: "scale4a_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  name: "res4a_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  name: "res4a_branch2b"
  type: "Convolution"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  name: "bn4a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  name: "scale4a_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res4a_branch1"
  bottom: "res4a_branch2b"
  top: "res4a"
  name: "res4a"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res4a"
  top: "res4a"
  name: "res4a_relu"
  type: "ReLU"
}

layer {
  bottom: "res4a"
  top: "res4b_branch2a"
  name: "res4b_branch2a"
  type: "Convolution"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  name: "bn4b_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  name: "scale4b_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  name: "res4b_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  name: "res4b_branch2b"
  type: "Convolution"
  convolution_param {
    num_output: 256
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  name: "bn4b_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  name: "scale4b_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res4a"
  bottom: "res4b_branch2b"
  top: "res4b"
  name: "res4b"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res4b"
  top: "res4b"
  name: "res4b_relu"
  type: "ReLU"
}

layer {
  bottom: "res4b"
  top: "res5a_branch1"
  name: "res5a_branch1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    kernel_size: 1
    pad: 0
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res5a_branch1"
  top: "res5a_branch1"
  name: "bn5a_branch1"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res5a_branch1"
  top: "res5a_branch1"
  name: "scale5a_branch1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res4b"
  top: "res5a_branch2a"
  name: "res5a_branch2a"
  type: "Convolution"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  name: "bn5a_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  name: "scale5a_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  name: "res5a_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  name: "res5a_branch2b"
  type: "Convolution"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  name: "bn5a_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  name: "scale5a_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res5a_branch1"
  bottom: "res5a_branch2b"
  top: "res5a"
  name: "res5a"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res5a"
  top: "res5a"
  name: "res5a_relu"
  type: "ReLU"
}

layer {
  bottom: "res5a"
  top: "res5b_branch2a"
  name: "res5b_branch2a"
  type: "Convolution"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
  name: "bn5b_branch2a"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
  name: "scale5b_branch2a"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
  name: "res5b_branch2a_relu"
  type: "ReLU"
}

layer {
  bottom: "res5b_branch2a"
  top: "res5b_branch2b"
  name: "res5b_branch2b"
  type: "Convolution"
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}

layer {
  bottom: "res5b_branch2b"
  top: "res5b_branch2b"
  name: "bn5b_branch2b"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}

layer {
  bottom: "res5b_branch2b"
  top: "res5b_branch2b"
  name: "scale5b_branch2b"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}

layer {
  bottom: "res5a"
  bottom: "res5b_branch2b"
  top: "res5b"
  name: "res5b"
  type: "Eltwise"
  eltwise_param {
    operation: SUM
  }
}

layer {
  bottom: "res5b"
  top: "res5b"
  name: "res5b_relu"
  type: "ReLU"
}

layer {
  name: "block6-conv2"
  type: "Convolution"
  bottom: "res5b"
  top: "block6-conv2"
  convolution_param {
    num_output: 512
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    pad: 1
    stride: 1
    bias_term: false
  }
}
layer {
  name: "block6-bn2"
  type: "BatchNorm"
  bottom: "block6-conv2"
  top: "block6-conv2"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}
layer {
  name: "block6-scale2"
  type: "Scale"
  bottom: "block6-conv2"
  top: "block6-conv2"
  scale_param {
    bias_term: true
    filler {
      value: 1.0
    }
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "block6-relu2"
  type: "ReLU"
  bottom: "block6-conv2"
  top: "block6-conv2"
}
layer {
  name: "yolo-out-m"
  type: "Convolution"
  bottom: "block6-conv2"
  top: "yolo-out-m"
  convolution_param {
    num_output: 75
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    pad: 0
    stride: 1
    bias_term: true
  }
}

layer {
  name: "upsampler_conv"
  type: "Convolution"
  bottom: "res5b"
  top: "upsampler"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    pad: 0
    stride: 1
    bias_term: false
  }
}
layer {
  name: "upsampler_bn"
  type: "BatchNorm"
  bottom: "upsampler"
  top: "upsampler"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}
layer {
  name: "upsampler-scale"
  type: "Scale"
  bottom: "upsampler"
  top: "upsampler"
  scale_param {
    bias_term: true
    filler {
      value: 1.0
    }
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "upsampler-relu"
  type: "ReLU"
  bottom: "upsampler"
  top: "upsampler"
}
layer {
  name: "upsampler-up"
  type: "Upsample"
  bottom: "upsampler"
  top: "upsampler_up"
  upsample_param: {
    scale: 2
  }
}
layer {
  name: "concat_upsampler"
  type: "Concat"
  bottom: "upsampler_up"
  bottom: "res4b"
  top: "concat_upsampler"
}
layer {
  name: "block7-conv0"
  type: "Convolution"
  bottom: "concat_upsampler"
  top: "block7-conv0"
  convolution_param {
    num_output: 256
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    pad: 1
    stride: 1
    bias_term: false
  }
}
layer {
  bottom: "block7-conv0"
  top: "block7-conv0"
  name: "block7-bn0"
  type: "BatchNorm"
  batch_norm_param {
    moving_average_fraction: 0.1
  }
}
layer {
  bottom: "block7-conv0"
  top: "block7-conv0"
  name: "block7-scale0"
  type: "Scale"
  scale_param {
    bias_term: true
    filler {
      value: 1.0
    }
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "block7-relu0"
  type: "ReLU"
  bottom: "block7-conv0"
  top: "block7-conv0"
}
layer {
  name: "yolo-out-s"
  type: "Convolution"
  bottom: "block7-conv0"
  top: "yolo-out-s"
  convolution_param {
    num_output: 75
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
    pad: 0
    stride: 1
    bias_term: true
  }
}

layer {
  name: "loss-s"
  type: "Yolov3"
  bottom: "yolo-out-s"
  bottom: "label"
  top: "loss-s"
  loss_weight: 1
  include {
    phase: TRAIN
  }
  yolov3_param {
    display: 800
    side: 26
    num_class: 20
    num: 3
    object_scale: 5.0
    noobject_scale: 1.0
    class_scale: 1.0
    coord_scale: 1.0
    thresh: 0.5
    anchors_scale : 16
    use_logic_gradient : false
    iou_loss: GIOU
    label_smooth_eps: 0.0
    biases: 23
    biases: 29
    biases: 48
    biases: 65
    biases: 68
    biases: 144
    biases: 126
    biases: 203
    biases: 204
    biases: 265
    biases: 326
    biases: 188
    mask:0
    mask:1
    mask:2
  }
}

layer {
  name: "loss-m"
  type: "Yolov3"
  bottom: "yolo-out-m"
  bottom: "label"
  top: "loss-m"
  loss_weight: 1
  include {
    phase: TRAIN
  }
  yolov3_param {
    display: 800
    side: 13
    num_class: 20
    num: 3
    object_scale: 5.0
    noobject_scale: 1.0
    class_scale: 1.0
    coord_scale: 1.0
    thresh: 0.5
    anchors_scale : 32
    use_logic_gradient : false
    iou_loss: GIOU
    label_smooth_eps: 0.0
    biases: 23
    biases: 29
    biases: 48
    biases: 65
    biases: 68
    biases: 144
    biases: 126
    biases: 203
    biases: 204
    biases: 265
    biases: 326
    biases: 188
    mask:3
    mask:4
    mask:5
  }
}

layer {
  name: "yolo_detection"
  type: "Yolov3DetectionOutput"
  bottom: "yolo-out-s"
  bottom: "yolo-out-m"
  top: "yolo_detection"
  include {
    phase: TEST
  }
  yolov3_detection_output_param {
    nms_threshold: 0.45
    num_classes: 20
    confidence_threshold: 0.01
    biases: 23
    biases: 29
    biases: 48
    biases: 65
    biases: 68
    biases: 144
    biases: 126
    biases: 203
    biases: 204
    biases: 265
    biases: 326
    biases: 188
    mask: 0
    mask: 1
    mask: 2
    mask: 3
    mask: 4
    mask: 5
    mask_group_num: 2
    anchors_scale: 16
    anchors_scale: 32
  }
}
layer {
  name: "yolo_eval"
  type: "DetectionEvaluate"
  bottom: "yolo_detection"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 21
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
  }
}
